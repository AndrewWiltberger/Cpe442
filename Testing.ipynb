{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2d3510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[7.0,0.27,0.36,20...|    6|\n",
      "|[6.3,0.3,0.34,1.6...|    6|\n",
      "|[8.1,0.28,0.4,6.9...|    6|\n",
      "|[7.2,0.23,0.32,8....|    6|\n",
      "|[7.2,0.23,0.32,8....|    6|\n",
      "|[8.1,0.28,0.4,6.9...|    6|\n",
      "|[6.2,0.32,0.16,7....|    6|\n",
      "|[7.0,0.27,0.36,20...|    6|\n",
      "|[6.3,0.3,0.34,1.6...|    6|\n",
      "|[8.1,0.22,0.43,1....|    6|\n",
      "|[8.1,0.27,0.41,1....|    5|\n",
      "|[8.6,0.23,0.4,4.2...|    5|\n",
      "|[7.9,0.18,0.37,1....|    5|\n",
      "|[6.6,0.16,0.4,1.5...|    7|\n",
      "|[8.3,0.42,0.62,19...|    5|\n",
      "|[6.6,0.17,0.38,1....|    7|\n",
      "|[6.3,0.48,0.04,1....|    6|\n",
      "|[6.2,0.66,0.48,1....|    8|\n",
      "|[7.4,0.34,0.42,1....|    6|\n",
      "|[6.5,0.31,0.14,7....|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"lrhp\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "df = spark.read.load('/container-data/winequality-white.csv',\n",
    "                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "#transform into [label, [features]] format\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_columns = df.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "from pyspark.sql.functions import col,row_number\n",
    "\n",
    "df_format = df.select(\"features\", \"quality\")\n",
    "df_format = df_format.withColumnRenamed(\"quality\", \"label\")\n",
    "df_format.show()\n",
    "\n",
    "training , test = df_format.randomSplit([0.8, 0.2], seed = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06eb0a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[3.8,0.31,0.02,11...|    6|[-9.8504628687002...|[2.63291837375996...|       6.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[3.8,0.31,0.02,11...|    6|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "\n",
    "#test the tunned mode LR\n",
    "loadedModel = CrossValidatorModel.load(\"LrModel\")\n",
    "loadedModel = loadedModel.bestModel\n",
    "predictions = loadedModel.transform(test)\n",
    "predictions.show(1)\n",
    "trainingSummary = predictions.summary\n",
    "test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3423e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (regParam):  0.01\n",
      "Best Param (MaxIter):  50\n",
      "Best Param (elasticNetParam):  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#extract the best parameters \n",
    "print ('Best Param (regParam): ', loadedModel._java_obj.getRegParam())\n",
    "print ('Best Param (MaxIter): ', loadedModel._java_obj.getMaxIter())\n",
    "print ('Best Param (elasticNetParam): ', loadedModel._java_obj.getElasticNetParam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61aad69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149958638742985"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get root mean squared error \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "dataset = predictions.select('label', 'prediction')\n",
    "evaluator = RegressionEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "evaluator.evaluate(dataset, {evaluator.metricName: \"rmse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################testing random forest now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5c5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[3.8,0.31,0.02,11...|    6|[0.0,0.0,0.0,0.01...|[0.0,0.0,0.0,0.00...|       6.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[3.8,0.31,0.02,11...|    6|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test the tunned model \n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "\n",
    "loadedModel = CrossValidatorModel.load(\"RfModel\")\n",
    "loadedModel = loadedModel.bestModel\n",
    "predictions = loadedModel.transform(test)\n",
    "predictions.show(1)\n",
    "\n",
    "trainingSummary = predictions.summary\n",
    "test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f71a0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (numTrees):  5\n"
     ]
    }
   ],
   "source": [
    "print ('Best Param (numTrees): ', loadedModel.getNumTrees )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd8f039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       6.0|  6.0|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "predictions_format = predictions.select(\"prediction\", \"label\")\n",
    "predictions_format = predictions_format.withColumn(\"label\", predictions_format[\"label\"].cast(\"double\"))\n",
    "predictions_format.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18b07a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.0, 6.0)\n",
      "(5.0, 5.0)\n",
      "(7.0, 7.0)\n",
      "(7.0, 5.0)\n",
      "(6.0, 7.0)\n"
     ]
    }
   ],
   "source": [
    "rdd = predictions_format.rdd.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "for element in rdd.take(5):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dde23c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lable:  1\n",
      "fMeasure: 0.00\n",
      "Lable:  2\n",
      "fMeasure: 0.00\n",
      "Lable:  3\n",
      "fMeasure:  0.0\n",
      "Lable:  4\n",
      "fMeasure:  0.0\n",
      "Lable:  5\n",
      "fMeasure:  0.5563909774436091\n",
      "Lable:  6\n",
      "fMeasure:  0.6253521126760564\n",
      "Lable:  7\n",
      "fMeasure:  0.31578947368421056\n",
      "Lable:  8\n",
      "fMeasure:  0.0\n",
      "Lable:  9\n",
      "fMeasure:  0.0\n",
      "Lable:  10\n",
      "fMeasure: 0.00\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(rdd)\n",
    "\n",
    "for x in range(1, 11, 1):\n",
    "    try:\n",
    "        print('Lable: ', x)\n",
    "        print('fMeasure: ',  metrics.fMeasure(float(x),1.0))\n",
    "    except:\n",
    "        print('fMeasure: 0.00')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
